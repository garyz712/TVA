TVA: a novel Token-aware Vision-transformer Accelerator. This is an outer-product-based attention inference engine with token-importance-driven mixed-precision quantization, processing each token with unique precision and latency.

**[Checkout the notebook for Quantization Aware Training and Post Training Quantization for TVA]([https://colab.research.google.com/drive/1MOoTyXWDp_eYIfNSExGwT0zUiHUOmrf6?usp=sharing](https://colab.research.google.com/drive/1kMJykQPWpzSrSdFVy_d5k_uMILESneGC?usp=sharing)**
